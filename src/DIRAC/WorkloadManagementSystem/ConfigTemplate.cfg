Services
{
  JobManager
  {
    Port = 9132
    MaxParametricJobs = 100
    Authorization
    {
      Default = authenticated
    }
  }
  ##BEGIN TornadoJobManager
  TornadoJobManager
  {
    Protocol = https
    Authorization
    {
      Default = authenticated
    }
  }
  ##END
  ##BEGIN TornadoPilotLogging
  TornadoPilotLogging
  {
    Protocol = https
    Authorization
    {
      Default = authenticated
      sendMessage = Operator
      sendMessage += GenericPilot
      getMetadata = Operator
      getMetadata += TrustedHost
      finaliseLogs = Operator
      finaliseLogs += Pilot
      finaliseLogs += GenericPilot
    }
  }
  ##END
  ##BEGIN JobMonitoring
  JobMonitoring
  {
    Port = 9130
    Authorization
    {
      Default = authenticated
    }
  }
  ##END
  ##BEGIN TornadoJobMonitoring
  TornadoJobMonitoring
  {
    Protocol = https
    Authorization
    {
      Default = authenticated
    }
  }
  ##END
  JobStateUpdate
  {
    Port = 9136
    Authorization
    {
      Default = authenticated
    }
    MaxThreads = 100
  }
  ##BEGIN TornadoJobStateUpdate
  TornadoJobStateUpdate
  {
    Protocol = https
    Authorization
    {
      Default = authenticated
    }
  }
  ##END
  #Parameters of the WMS Matcher service
  Matcher
  {
    Port = 9170
    MaxThreads = 20
    Authorization
    {
      Default = authenticated
      getActiveTaskQueues = JobAdministrator
    }
  }
  #Parameters of the WMS Administrator service
  WMSAdministrator
  {
    Port = 9145
    Authorization
    {
      Default = Operator
      getJobPilotOutput = authenticated
    }
  }
  ##BEGIN TornadoWMSAdministrator
  TornadoWMSAdministrator
  {
    Protocol = https
    Authorization
    {
      Default = Operator
      getJobPilotOutput = authenticated
    }
  }
  ##END
  #Parameters of the PilotManager service
  PilotManager
  {
    Port = 9171
    Authorization
    {
      Default = authenticated
    }
  }
  ##BEGIN SandboxStore
  SandboxStore
  {
    Port = 9196
    LocalSE = ProductionSandboxSE
    MaxThreads = 200
    MaxSandboxSizeMiB = 10
    BasePath = /opt/dirac/storage/sandboxes
    # If true, uploads the sandbox via diracx on an S3 storage
    UseDiracXBackend = False
    Authorization
    {
      Default = authenticated
      FileTransfer
      {
        Default = authenticated
      }
    }
  }
  ##END
  ##BEGIN TornadoSandboxStore
  TornadoSandboxStore
  {
    Protocol = https
    LocalSE = ProductionSandboxSE
    MaxThreads = 200
    MaxSandboxSizeMiB = 10
    BasePath = /opt/dirac/storage/sandboxes
    Authorization
    {
      Default = authenticated
      FileTransfer
      {
        Default = authenticated
      }
    }
  }
  ##END
  OptimizationMind
  {
    Port = 9175
  }
}
Agents
{
  ##BEGIN PilotSyncAgent
  PilotSyncAgent
  {
    PollingTime = 600
    # Directory where the files can be moved. If running on the WebApp, use /opt/dirac/webRoot/www/pilot
    SaveDirectory =
    # List of locations where to upload the pilot files. Can be https://some.where, or DIRAC SE names.
    UploadLocations =
    # Set to False (or No, or N) to exclude the master CS from the list of CS servers
    IncludeMasterCS = True
  }
  ##END
  ##BEGIN PilotStatusAgent
  PilotStatusAgent
  {
    PollingTime = 300
    # Flag enabling sending of the Pilot accounting info to the Accounting Service
    PilotAccountingEnabled = yes
  }
  ##END
  ##BEGIN PilotLoggingAgent
  PilotLoggingAgent
  {
    PollingTime = 600
  }
  ##END
  JobAgent
  {
    PollingTime = 20
    FillingModeFlag = true
    StopOnApplicationFailure = true
    StopAfterFailedMatches = 10
    StopAfterHostFailures = 3
    SubmissionDelay = 10
    DefaultLogLevel = INFO
    JobWrapperTemplate = DIRAC/WorkloadManagementSystem/JobWrapper/JobWrapperTemplate.py
  }
  ##BEGIN StalledJobAgent
  StalledJobAgent
  {
    StalledTimeHours = 2
    FailedTimeHours = 6
    PollingTime = 3600
    MaxNumberOfThreads = 15
    # List of sites for which we want to be more tolerant before declaring the job stalled
    StalledJobsTolerantSites =
    StalledJobsToleranceTime = 0
    # List of sites for which we want to be Reschedule (instead of declaring Failed) the Stalled jobs
    StalledJobsToRescheduleSites =
    SubmittingTime = 300
    MatchedTime = 7200
    RescheduledTime = 600
    Enable = True
  }
  ##END
  ##BEGIN JobCleaningAgent
  JobCleaningAgent
  {
    PollingTime = 3600

    #Maximum number of jobs to be processed in one cycle
    MaxJobsAtOnce = 500

    # Maximum number of jobs to be processed in one cycle for HeartBeatLoggingInfo removal
    MaxHBJobsAtOnce = 0

    RemoveStatusDelay
    {
       # Number of days after which Done jobs are removed
       Done = 7
       # Number of days after which Killed jobs are removed
       Killed = 7
       # Number of days after which Failed jobs are removed
       Failed = 7
       # Number of days after which any jobs, irrespective of status is removed (-1 for disabling this feature)
       Any = -1
    }

    RemoveStatusDelayHB
    {
       # Number of days after which HeartBeatLoggingInfo for Done jobs are removed, positive to enable
       Done = -1
       # Number of days after which HeartBeatLoggingInfo for Killed jobs are removed
       Killed = -1
       # Number of days after which HeartBeatLoggingInfo for Failed jobs are removed
       Failed = -1
    }

    # Which production type jobs _not_ to remove, takes default from Operations/Transformations/DataProcessing
    ProductionTypes =
  }
  ##END
  ##BEGIN SiteDirector
  SiteDirector
  {
    # VO treated (leave empty for auto-discovery)
    VO =
    # VO treated (leave empty for auto-discovery)
    Community =
    # the DN of the certificate proxy used to submit pilots. If not found here, what is in Operations/Pilot section of the CS will be used
    PilotDN =

    # List of sites that will be treated by this SiteDirector (No value can refer to any Site defined in the CS)
    Site =
    # List of CEs that will be treated by this SiteDirector (No value can refer to any CE defined in the CS)
    CEs =
    # List of CE types that will be treated by this SiteDirector (No value can refer to any type of CE defined in the CS)
    CETypes =
    # List of Tags that are required to be present in the CE/Queue definition
    Tags =

    # How many cycles to skip if queue is not working
    FailedQueueCycleFactor = 10
    # Every N cycles, pilot status update is performed by the SiteDirector
    PilotStatusUpdateCycleFactor = 10
    # Every N cycles, pilot submission is performed by the SiteDirector
    PilotSubmissionCycleFactor = 1
    # The maximum length of a queue (in seconds). Default: 3 days
    MaxQueueLength = 259200
    # Max number of pilots to submit per cycle
    MaxPilotsToSubmit = 100
    # Boolean value that indicates if the pilot job will send information for accounting
    SendPilotAccounting = True
    # Working directory containing the pilot files if not set in the CE
    WorkDirectory =
  }
  ##END
  ##BEGIN PushJobAgent
  PushJobAgent
  {
    # VO treated (leave empty for auto-discovery)
    VO =
    # The DN of the certificate proxy used to submit pilots/jobs. If not found here, what is in Operations/Pilot section of the CS will be used
    PilotDN =

    # List of sites that will be treated by this PushJobAgent ("any" can refer to any Site defined in the CS)
    Site =
    # List of CE types that will be treated by this PushJobAgent ("any" can refer to any CE defined in the CS)
    CETypes =
    # List of CEs that will be treated by this PushJobAgent ("any" can refer to any CE type defined in the CS)
    CEs =

    # Max number of jobs to handle simultaneously
    MaxJobsToSubmit = 100
    # How many cycels to skip if queue is not working
    FailedQueueCycleFactor = 10
    # How the agent manages the submission of the jobs
    SubmissionPolicy = JobWrapper
    # The CVMFS location to be used for the job execution on the remote site
    CVMFSLocation = "/cvmfs/dirac.egi.eu/dirac/pro"
    # Clean the task after the job is done
    CleanTask = True
  }
  ##END
  ##BEGIN StatesAccountingAgent
  StatesAccountingAgent
  {
    # the name of the message queue used for the failover
    MessageQueue = dirac.wmshistory
    # Polling time. For this agent it should always be 15 minutes.
    PollingTime = 900
  }
  ##END
  ##BEGIN TaskQueuesAgent
  TaskQueuesAgent
  {
    PollingTime = 120
  }
  ##END
}
Executors
{
  Optimizers
  {
    Load = JobPath, JobSanity, InputData, JobScheduling
  }
  JobPath
  {

  }
  JobSanity
  {

  }
  InputData
  {

  }
  JobScheduling
  {

  }
}
##BEGIN JobWrapper
JobWrapper
{
  BufferLimit = 10485760
  CleanUpFlag = True
  DefaultCatalog = []
  DefaultCPUTime = 600
  DefaultErrorFile = 'std.err'
  DefaultOutputFile = 'std.out'
  DiskSE = ['-disk', '-DST', '-USER']
  MasterCatalogOnlyFlag = True
  MaxJobPeekLines = 20
  OutputSandboxLimit = 1024 * 1024 * 10
  # Retry the upload of the output file if only one output SE is defined
  RetryUpload = False
  TapeSE = ['-tape', '-RDST', '-RAW']
  MinOutputDataBufferGB = 5
}
##END
